{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9f47f2-d57f-4f52-be0c-6243840ba3a8",
   "metadata": {},
   "source": [
    "## Занятие 4. Разработка ml проектов: хорошие и плохие практики\n",
    "На занятии 3 мы написали пайплайн обучения семантического сегментатора подводных фото в одном jupyter ноутбуке.\n",
    "\n",
    "На этом занятии мы оформим этот пайплайн в ml проект так, чтобы его можно было поддерживать и развивать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f474e98a-fa1b-42a3-a808-e5d6ffb96fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/edu/course_cvdl/classes/c04')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ROOT_PATH = Path().absolute()\n",
    "assert ROOT_PATH.name == 'c04', ROOT_PATH.name\n",
    "ROOT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cafa43-251b-40c3-8151-7114fded5a6d",
   "metadata": {},
   "source": [
    "### Плохая практика 1: использование jupyter ноутбуков в качестве основного средства разработки\n",
    "- https://www.kdnuggets.com/2019/11/notebook-anti-pattern.html\n",
    "- https://analyticsindiamag.com/an-argument-against-using-jupyter-notebook-for-machine-learning/\n",
    "- https://medium.com/skyline-ai/jupyter-notebook-is-the-cancer-of-ml-engineering-70b98685ee71\n",
    "\n",
    "Главные проблемы:\n",
    "- нелинейность исполнения кода (сложно читать и сложно воспроизводить)\n",
    "- невозможность тестирования\n",
    "- нечитыемые diff-ы в git (сложно разобраться в истории и работать совместно)\n",
    "\n",
    "Jupyter ноутбуки хорошо подходят чтобы:\n",
    "- визуализировать данные\n",
    "- набросать прототип\n",
    "- поделиться однократным результатом\n",
    "\n",
    "\n",
    "#### **Решение**: \n",
    "Использовать стандартные инструменты разработки ЯП, например - Python пакеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c30f053-ecfb-4cdf-8054-96544bef8e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'suim_segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Python ищет пакеты в PYTHONPATH, если пакет не найден - то получаем ModuleNotFound\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msuim_segmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SuimDataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'suim_segmentation'"
     ]
    }
   ],
   "source": [
    "# Python ищет пакеты в PYTHONPATH, если пакет не найден - то получаем ModuleNotFound\n",
    "from suim_segmentation.data import SuimDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fa5c9a-2e90-40ba-b050-61b163fae416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\edu\\course_cvdl\\classes\\c04\\src\n"
     ]
    }
   ],
   "source": [
    "cd {ROOT_PATH}/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3d451e-4c00-4eef-be47-c8b66d06c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В PYTHONPATH всегда содержится current_dir, так что из родительской директории можно импортировать пакет\n",
    "from suim_segmentation.data import SuimDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136bd506-722c-4b8f-abe3-17af6d715975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\edu\\\\course_cvdl\\\\classes\\\\c04\\\\src\\\\suim_segmentation\\\\data.py'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from suim_segmentation import data as suim_data\n",
    "suim_data.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee323b2e-bb7a-4e43-9e21-95f3cc701a80",
   "metadata": {},
   "source": [
    "Если пакет находится в текущей папке, то его можно импортировать.\n",
    "\n",
    "Это не очень удобно - код можно будет вызывать только при определенной текущей директории.\n",
    "\n",
    "**Правильное решение - сделать пакет устанавливаемым!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5b14e-4368-444d-b262-909b271795a5",
   "metadata": {},
   "source": [
    "### 1.1 Пакетируем код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4531b8-82d7-4b3c-a25c-fcd108be5dc0",
   "metadata": {},
   "source": [
    "На сегодня (2023 год) [рекомендуется](https://packaging.python.org/en/latest/tutorials/packaging-projects/#creating-pyproject-toml) пакетировать код с помощью `pyproject.toml` файла:\n",
    "- поддерживает разные системы сборки (не только setuptools)\n",
    "- поддерживает C++ расширения\n",
    "- стандартизирован в PEP-518, PEP-621\n",
    "\n",
    "Раньше часто использовались другие [способы](https://packaging.python.org/en/latest/glossary/?highlight=setup.py#term-setup.py), но сейчас `pyproject.toml` является рекомендуемым"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e04ff4e3-d121-43d6-892b-451b8f2f726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Ext\n",
      " Volume Serial Number is 5670-7B72\n",
      "\n",
      " Directory of D:\\edu\\course_cvdl\\classes\\c04\\src\n",
      "\n",
      "01.10.2023  17:13    <DIR>          .\n",
      "01.10.2023  17:13    <DIR>          ..\n",
      "01.10.2023  17:13    <DIR>          suim_segmentation\n",
      "               0 File(s)              0 bytes\n",
      "               3 Dir(s)  351я745я527я808 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f740855-b6c8-4d63-b1fa-613c154432ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing D:\\edu\\course_cvdl\\classes\\c04\\src\\pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {str(ROOT_PATH / 'src' / 'pyproject.toml')}\n",
    "\n",
    "[project]\n",
    "name = \"suim_segmentation\"\n",
    "description = \"ML project example package\"\n",
    "version = \"0.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d4f38-4e50-4102-bd49-aefa9939d83f",
   "metadata": {},
   "source": [
    "### Готово - пакет стал устанавливаемым\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5dd9dfd-6cf6-4081-85ad-4680c32d9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Ext\n",
      " Volume Serial Number is 5670-7B72\n",
      "\n",
      " Directory of D:\\edu\\course_cvdl\\classes\\c04\\src\n",
      "\n",
      "01.10.2023  17:18    <DIR>          .\n",
      "01.10.2023  17:18    <DIR>          ..\n",
      "01.10.2023  17:18    <DIR>          .ipynb_checkpoints\n",
      "01.10.2023  17:18               104 pyproject.toml\n",
      "01.10.2023  17:13    <DIR>          suim_segmentation\n",
      "               1 File(s)            104 bytes\n",
      "               4 Dir(s)  351я745я527я808 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "368e424f-90c8-4336-b0f4-3eb78821c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///D:/edu/course_cvdl/classes/c04/src\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: suim-segmentation\n",
      "  Building editable for suim-segmentation (pyproject.toml): started\n",
      "  Building editable for suim-segmentation (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for suim-segmentation: filename=suim_segmentation-0.1.0-0.editable-py3-none-any.whl size=2665 sha256=29b3bd15c320609e4e13fa659ae1830b72b0801cdccf6d5fb73d0c72a0b26a84\n",
      "  Stored in directory: C:\\Users\\bzimka\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-bluz1ha3\\wheels\\48\\5e\\2b\\574c8018a0d55301b24c6ce052454fd787d602cce8c29cc720\n",
      "Successfully built suim-segmentation\n",
      "Installing collected packages: suim-segmentation\n",
      "Successfully installed suim-segmentation-0.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c744fe-cf03-46fd-8db8-581e533e2360",
   "metadata": {},
   "source": [
    "Ещё пакеты c `pyproject.toml` (или `setup.py`) можно устанавливать из git репозитория, например:\n",
    "`pip install git+https://github.com/arogozhnikov/einops`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062383ca-55c5-4351-b58a-b5f10be2b037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\edu\\course_cvdl\\classes\\c04\n"
     ]
    }
   ],
   "source": [
    "cd {ROOT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31152be1-8cde-4831-bc5d-5977379f22bc",
   "metadata": {},
   "source": [
    "## Restart KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd6f5c0-a7db-44b6-8e08-9f6baf892cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/edu/course_cvdl/classes/c04')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ROOT_PATH = Path().absolute()\n",
    "assert ROOT_PATH.name == 'c04', ROOT_PATH.name\n",
    "ROOT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7b8f76-1830-4b0d-a237-70bf1327cb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\edu\\\\course_cvdl\\\\classes\\\\c04\\\\src\\\\suim_segmentation\\\\data.py'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from suim_segmentation.data import SuimDataset\n",
    "from suim_segmentation import data\n",
    "data.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a2c588-9dad-4e78-b382-041136ab5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Ext\n",
      " Volume Serial Number is 5670-7B72\n",
      "\n",
      " Directory of D:\\edu\\course_cvdl\\classes\\c04\n",
      "\n",
      "01.10.2023  17:21    <DIR>          .\n",
      "01.10.2023  17:21    <DIR>          ..\n",
      "01.10.2023  12:29                27 .gitignore\n",
      "30.09.2023  21:16    <DIR>          .ipynb_checkpoints\n",
      "01.10.2023  17:21            88я955 c04.ipynb\n",
      "01.10.2023  17:04    <DIR>          data\n",
      "10.09.2023  10:25           645я578 dvc_scheme.png\n",
      "10.09.2023  10:25               309 README.md\n",
      "01.10.2023  17:20    <DIR>          src\n",
      "               4 File(s)        734я869 bytes\n",
      "               5 Dir(s)  351я745я511я424 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7162ffa-9e09-4289-980e-98026cf43474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\edu\\course_cvdl\\classes\\c04\\src\n"
     ]
    }
   ],
   "source": [
    "cd {ROOT_PATH/\"src\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbcfc22-045d-45db-b973-a85d5bb051c0",
   "metadata": {},
   "source": [
    "### 1.1 Проверяем код на PEP-8 с помощью `pylint`\n",
    "Pylint - инструмент для проверки кода на соответствие PEP-8.\n",
    "\n",
    "`pip install pylint`\n",
    "\n",
    "Вывод всех нарушений PEP8 и оценки вашего кода: `python -m pylint suim_segmentation`\n",
    "\n",
    "Вывод только ошибок: `python -m pylint suim_segmentation/ -E`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2932d1f-519e-47c6-be11-a824ab66960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pylint suim_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf2af7-b1c0-44ae-a1cd-5be208025b99",
   "metadata": {},
   "source": [
    "### 1.2 Форматируем код с помощью [black](https://github.com/psf/black) и [isort](https://github.com/PyCQA/isort)\n",
    "Часть ошибок форматирования можно поправить автоматически с помощью black и isort.\n",
    "\n",
    "`pip install black isort`\n",
    "\n",
    "Форматирование: \n",
    "- `python -m black suim_segmentation/`\n",
    "- `python -m isort suim_segmentation/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c64f984-69ab-4222-85a6-664a253c97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reformatted D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\metrics.py\n",
      "\n",
      "All done! \\u2728 \\U0001f370 \\u2728\n",
      "1 file reformatted, 5 files left unchanged.\n"
     ]
    }
   ],
   "source": [
    "! python -m black src/suim_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b75d60-4def-47f8-8fd6-74fd0ccc5338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\data.py\n",
      "Fixing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\model.py\n",
      "Fixing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\trainer.py\n",
      "Fixing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\.ipynb_checkpoints\\data-checkpoint.py\n",
      "Fixing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\.ipynb_checkpoints\\model-checkpoint.py\n"
     ]
    }
   ],
   "source": [
    "! python -m isort src/suim_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeef919-363d-4645-8445-2841bab8a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pylint suim_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f24f1-c7d4-4f34-a38e-95312dc9b5da",
   "metadata": {},
   "source": [
    "### 1.3 Тюним правил PEP-8 под свой проект\n",
    "Для pylint можно создать набор правил и указать его в `pyproject.toml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada0d969-af06-48a3-8896-48a2a78cfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ROOT_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49469e31-c112-427b-b013-5331c8ff36e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting D:\\edu\\course_cvdl\\classes\\c04\\src\\pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {str(ROOT_PATH / 'src' / 'pyproject.toml')}\n",
    "\n",
    "[project]\n",
    "name = \"suim_segmentation\"\n",
    "description = \"ML project example package\"\n",
    "version = \"0.1.0\"\n",
    "\n",
    "[tool.pylint]\n",
    "good-names = \"b,h,w,x,tp,fp,fn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "708a19f0-ee86-46f4-9219-5ac4553fbd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\edu\\course_cvdl\\classes\\c04\\src\n"
     ]
    }
   ],
   "source": [
    "cd {ROOT_PATH/\"src\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fc2a0-b09d-4cf2-a655-d3a59a6fee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pylint suim_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9badc7b-85be-4d53-808f-7bc330500f92",
   "metadata": {},
   "source": [
    "### 1.4 Пишем \"точку входа\" в пайплайн (скрипт обучения) \n",
    "Собираем код с прошлого занятия для запуска пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b08e829a-4e23-498d-be97-8b2c337d6080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {str(ROOT_PATH / 'src' / 'suim_segmentation' / 'run.py')}\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as tdata\n",
    "from tqdm import tqdm\n",
    "\n",
    "from .data import SuimDataset, EveryNthFilterSampler\n",
    "from .model import SuimModel\n",
    "from .loss import DiceLoss\n",
    "from .metrics import Accuracy\n",
    "from .trainer import Trainer\n",
    "\n",
    "PROJECT_NAME = 'suim_segmentation2023'\n",
    "\n",
    "\n",
    "def run_pipeline(args):\n",
    "    device = torch.device(args.device)\n",
    "    model = SuimModel().to(device)\n",
    "    model.encoder.requires_grad_(False)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    train_val_ds = SuimDataset(\n",
    "        Path(args.train_data), masks_as_color=False, target_size=(256, 256)\n",
    "    )\n",
    "    test_ds = SuimDataset(\n",
    "        Path(args.test_data), masks_as_color=False, target_size=(256, 256)\n",
    "    )\n",
    "    test_iter = tdata.DataLoader(test_ds, batch_size=args.batch_size, shuffle=False)\n",
    "    train_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=False, shuffle=True\n",
    "        ),\n",
    "    )\n",
    "    val_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=True, shuffle=False\n",
    "        ),\n",
    "    )\n",
    "    loss = DiceLoss()\n",
    "    metric = Accuracy()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        net=model,\n",
    "        opt=opt,\n",
    "        train_loader=train_iter,\n",
    "        val_loader=val_iter,\n",
    "        test_loader=test_iter,\n",
    "        loss=loss,\n",
    "        metric=metric,\n",
    "    )\n",
    "    mean = lambda x: sum(x) / len(x)\n",
    "\n",
    "    for e in range(args.num_epochs):\n",
    "        print(f\"Epoch {e}\")\n",
    "        with_testing = (e == args.num_epochs - 1)\n",
    "        epoch_stats = trainer(num_epochs=1, with_testing=with_testing)\n",
    "        train_loss, train_metric = epoch_stats['train'][0]\n",
    "        val_loss, val_metric = epoch_stats['val'][0]\n",
    "        assert isinstance(train_loss, list), type(train_loss)\n",
    "\n",
    "    test_loss, test_metric = epoch_stats['test'][0]\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--name\", type=str, required=True)\n",
    "    parser.add_argument(\"--train-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--test-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--lr\", type=float, required=True)\n",
    "    parser.add_argument(\"--num-epochs\", type=int, required=True)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--device\", type=str, default='cpu:0')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    run_pipeline(args)\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c57f43-2d5a-49e8-9277-56f389938e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m suim_segmentation.run --name=baseline --lr=0.03 --num-epochs=1 --batch-size=32 --device=cpu:0 \\\n",
    "    --train-data={ROOT_PATH}\\data\\train_val \\\n",
    "    --test-data={ROOT_PATH}\\data\\TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e2244-ad23-4c86-9cb1-12ba80bb0b48",
   "metadata": {},
   "source": [
    "### Плохая практика 2: \"ручное\" копирование данных\n",
    "\n",
    "- В реальных проектах (индустрия/соревнования) часто используется несколько датасетов, а не один\n",
    "- Они могут быть в разных форматах, а код проекта обычно работает только с одним форматом\n",
    "- Датасет может обновляться - даже у ImageNet есть [version2](https://proceedings.mlr.press/v97/recht19a/recht19a.pdf)\n",
    "- Часто датасет нужен на разных машинах (например, локальной и devbox с GPU)\n",
    "\n",
    "#### **Решение**: \n",
    "Использовать инструменты для управления данными, например - [dvc](https://dvc.org)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a87f01d-a1b0-4daa-bb22-35e6c29f55c0",
   "metadata": {},
   "source": [
    "! pip install dvc[gdrive]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbee11b-59f9-40f6-b01b-9319f40fff79",
   "metadata": {},
   "source": [
    "![dvc scheme was not loaded](dvc_scheme.png \"DVC scheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f50b2-9f29-4012-945a-1d25f12e1d54",
   "metadata": {},
   "source": [
    "### 2.1 Добавляем google-drive в качестве хранилища\n",
    "\n",
    "https://dvc.org/doc/user-guide/how-to/setup-google-drive-remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b28365f2-95e1-4593-9b39-905ea9826c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\edu\\course_cvdl\\classes\\c04\\data\n"
     ]
    }
   ],
   "source": [
    "cd {ROOT_PATH}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15353e68-28fd-4c15-a652-cc7d2a4912c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "! dvc init --subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60543b7a-bba9-427a-abcb-7facaf54b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! dvc remote add mygoogledrive gdrive://1_8FVmJgPW-dwYr8jOe9PQupCEy53WQ4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2f8e260-8a1e-461f-ba23-c09f3547ff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mygoogledrive\tgdrive://1_8FVmJgPW-dwYr8jOe9PQupCEy53WQ4d\n"
     ]
    }
   ],
   "source": [
    "! dvc remote list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d2879-dfbe-4252-ad27-6482e8891aa6",
   "metadata": {},
   "source": [
    "Добавим test-данные в индекс dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f293ce0c-8b84-4b76-b320-74ba89fc9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Ext\n",
      " Volume Serial Number is 5670-7B72\n",
      "\n",
      " Directory of D:\\edu\\course_cvdl\\classes\\c04\\data\n",
      "\n",
      "01.10.2023  17:42    <DIR>          .\n",
      "01.10.2023  17:42    <DIR>          ..\n",
      "01.10.2023  17:42    <DIR>          .dvc\n",
      "01.10.2023  17:42               142 .dvcignore\n",
      "30.09.2023  22:18                26 .gitignore\n",
      "30.09.2023  18:28    <DIR>          test\n",
      "30.09.2023  19:23    <DIR>          train_val\n",
      "               2 File(s)            168 bytes\n",
      "               5 Dir(s)  351я603я404я800 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cdebe7c-a930-4b83-b08a-cbbf9ced4c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add test.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u280b Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! dvc add test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7b575-4c9f-45bb-ad4f-5a6a9168de35",
   "metadata": {},
   "source": [
    "Отправим данные в хранилище"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "493d5b8b-795d-4f12-bbb2-7adb4cd72fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551 files pushed\n"
     ]
    }
   ],
   "source": [
    "! dvc push test.dvc --remote=mygoogledrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ecf6c-1a18-418c-9897-7ef56b261c67",
   "metadata": {},
   "source": [
    "Тперь можно сохранить \"ссылки\" на данные в git.\n",
    "```\n",
    "! git add data/\n",
    "! git commit -m \"Add data with DVC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7cde91b-f9d7-46ee-9ebb-fa9059b18469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A       test\\\n",
      "1 file added\n"
     ]
    }
   ],
   "source": [
    "# скачаем данные test\n",
    "! dvc pull test.dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7063f29-d99e-4f59-9b41-9d976291f6e1",
   "metadata": {},
   "source": [
    "### Плохая практика 3: проведение экспериментов без отслеживания результатов\n",
    "Достижение лучшх результатов в любой ml-задаче требует множество экспериментов, каждый из которых дает небольшое улучшение (или ухудшение).\n",
    "\n",
    "Результаты экспериментов необходимо сравнивать между собой, чтобы оставлять успешные идеи и отбрасывать неудачные.\n",
    "\n",
    "Простейший (ручной) способ отслеживания экспериментов:\n",
    "- выполнили эксперимент N, запомнили метрики\n",
    "- выполнили эксперимент N+1, сравнили метрики с N, запомнили\n",
    "- выполнили эксперимент N+2, сравнили метрики с N+1, запомнили\n",
    "- ...\n",
    "\n",
    "Главная проблема: **после эксперимента не остаётся следов (артефактов)**\n",
    "\n",
    "Проблемы-следствия:\n",
    "- нельзя сравнить результаты эксперименты N и (N+10) \n",
    "- сложно провести многовариантный, а не бинарный эксперимент\n",
    "- сложно воспроизвести идею N (если она стала снова актуальной)\n",
    "- нужно держать в голове, насколько хорощо/плохо сработала идея когда-то в прошлом\n",
    "\n",
    "**Решение:** Логировать все параметры и результаты эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11748159-56e2-4e75-8922-75a7e0ef4449",
   "metadata": {},
   "source": [
    "### 3.1 Подключаем Weights & Biases\n",
    "https://docs.wandb.ai/quickstart\n",
    "\n",
    "1. Устанавливаем wandb: `! pip install wandb`\n",
    "2. Авторизуемся на `https://wandb.ai/login` (например, через GitHub)\n",
    "3. Заходим на `https://wandb.ai/settings`, копируем ключ из `API keys`\n",
    "4. Выполняем `$ wandb login <YOUR API KEY>` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411b771-f9e1-4b75-974e-55ba88445064",
   "metadata": {},
   "source": [
    "### 3.2 Проверяем wnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c83b3217-f257-4287-ba02-f2b3f259acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5721f289-f938-454c-9b8f-3ad796900f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzimka\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\edu\\course_cvdl\\classes\\c04\\data\\wandb\\run-20231001_180442-d7yz0nx0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zimka/c04/runs/d7yz0nx0' target=\"_blank\">second</a></strong> to <a href='https://wandb.ai/zimka/c04' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zimka/c04' target=\"_blank\">https://wandb.ai/zimka/c04</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zimka/c04/runs/d7yz0nx0' target=\"_blank\">https://wandb.ai/zimka/c04/runs/d7yz0nx0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/zimka/c04/runs/d7yz0nx0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x146a656e380>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='c04', config={'lr': 0.01, 'foo': 'bar', 'something': True}, name='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694c34d-d74c-4a3f-9763-c034e3e59073",
   "metadata": {},
   "source": [
    "Можно логировать численные величины. Каждое вызов log неявно увеличивает внутренний счётчик шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "152b9a60-9163-44e0-8268-4565ac82d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.9, \"metric\": 0.5}, \"val\": {\"loss\": 0.4, \"acc\": 0.8}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d743e0f3-2b53-4cc9-8faf-9f90586e74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.8, \"metric\": 0.5}, \"val\": {\"loss\": 0.35, \"acc\": 0.8}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44b05a8e-5501-4e76-b37b-1f26a24502b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.75, \"metric\": 0.52}, \"val\": {\"loss\": 0.33, \"acc\": 0.7}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a95bca63-1b30-435e-83cb-5913a3d0798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.74, \"metric\": 0.52}, \"val\": {\"loss\": 0.32, \"acc\": 0.7}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a29970-f4fb-446d-afef-a66860eb6711",
   "metadata": {},
   "source": [
    "Можно явно указать шаг, к которому относится запись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc9f2ba3-964e-49ce-bd69-5c011e96929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.74, \"metric\": 0.52}, \"val\": {\"loss\": 0.32, \"acc\": 0.7}}, step=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1958c60-07fd-432d-bb1b-77c6d3e3e07a",
   "metadata": {},
   "source": [
    "Каждый вызов log добавляет аргументы во внутреннее состояние и коммитит **предыдущие** значения.\n",
    "\n",
    "Можно считать, что каждый вызов .log - это `git commit` старых данных + `git add` новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0d1ff7d-2913-4fe2-8914-1ed0789639b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"train\": {\"loss\": 0.74, \"metric\": 0.52}, \"val\": {\"loss\": 0.32, \"acc\": 0.7}}, step=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa92a7-8696-4f35-9b4f-eff04e0b55b0",
   "metadata": {},
   "source": [
    "Можно логировать не только численные величины - например, изображения с масками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b8ef787-4b23-4fbc-ac36-c44081fd5dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "110it [00:01, 79.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from suim_segmentation.data import SuimDataset\n",
    "\n",
    "test_data = SuimDataset(root=ROOT_PATH / 'data' / 'TEST', masks_as_color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc84f73f-5bd3-4e27-a54d-8c7919ea0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img, y_mask = test_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "208f3073-a818-495e-9185-9a1abddd7196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Background(waterbody)', '000'),\n",
       " ('Human divers', '001'),\n",
       " ('Aquatic plants and sea-grass', '010'),\n",
       " ('Wrecks and ruins', '011'),\n",
       " ('Robots (AUVs/ROVs/instruments)', '100'),\n",
       " ('Reefs and invertebrates', '101'),\n",
       " ('Fish and vertebrates', '110'),\n",
       " ('Sea-floor and rocks', '111'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SuimDataset.LABEL_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0ad66a4-bfda-4784-87b3-39ff0564762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = dict(\n",
    "    (num, cls_name) for num, (cls_name, binary_idx) in enumerate(SuimDataset.LABEL_COLORS)\n",
    ")\n",
    "\n",
    "mask_img = wandb.Image(x_img.permute(1, 2, 0).numpy(), masks={\n",
    "  \"predictions\": {\n",
    "    \"mask_data\": y_mask[0].numpy(),\n",
    "    \"class_labels\": class_labels\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "058d7130-4476-4c7b-815e-5c8b08e9f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"gt_example\": mask_img}, commit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c9de1-5587-40cc-8062-d0e72c751b60",
   "metadata": {},
   "source": [
    "Можно добавить ключ-значение в summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d7e9751-448e-4ba0-8a40-7687198bd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary['my_key'] = 'my_important_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26a0a767-fe2c-4111-b7f3-133b068ab976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>my_key</td><td>my_important_value</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">second</strong> at: <a href='https://wandb.ai/zimka/c04/runs/d7yz0nx0' target=\"_blank\">https://wandb.ai/zimka/c04/runs/d7yz0nx0</a><br/>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231001_180442-d7yz0nx0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c64437-2cdb-4694-96d3-b8939b443fcf",
   "metadata": {},
   "source": [
    "### Залогируем параметры и результаты эксперимента\n",
    "Дописать код run.py так, чтобы логировались (как минимум):\n",
    "- Средние train.loss, train.metric, val.loss, val.metric для каждой эпохи\n",
    "- Средние test.loss, test.metric однократно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74c70376-1566-4024-a075-163f45b7139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting D:\\edu\\course_cvdl\\classes\\c04\\src\\suim_segmentation\\run.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {str(ROOT_PATH / 'src' / 'suim_segmentation' / 'run.py')}\n",
    "import wandb\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as tdata\n",
    "from tqdm import tqdm\n",
    "\n",
    "from .data import SuimDataset, EveryNthFilterSampler\n",
    "from .model import SuimModel\n",
    "from .loss import DiceLoss\n",
    "from .metrics import Accuracy\n",
    "from .trainer import Trainer\n",
    "\n",
    "PROJECT_NAME = 'suim_segmentation2023'\n",
    "\n",
    "\n",
    "def run_pipeline(args):\n",
    "    device = torch.device(args.device)\n",
    "    model = SuimModel().to(device)\n",
    "    model.encoder.requires_grad_(False)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    train_val_ds = SuimDataset(\n",
    "        Path(args.train_data), masks_as_color=False, target_size=(256, 256)\n",
    "    )\n",
    "    test_ds = SuimDataset(\n",
    "        Path(args.test_data), masks_as_color=False, target_size=(256, 256)\n",
    "    )\n",
    "    test_iter = tdata.DataLoader(test_ds, batch_size=args.batch_size, shuffle=False)\n",
    "    train_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=False, shuffle=True\n",
    "        ),\n",
    "    )\n",
    "    val_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=True, shuffle=False\n",
    "        ),\n",
    "    )\n",
    "    loss = DiceLoss()\n",
    "    metric = Accuracy()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        net=model,\n",
    "        opt=opt,\n",
    "        train_loader=train_iter,\n",
    "        val_loader=val_iter,\n",
    "        test_loader=test_iter,\n",
    "        loss=loss,\n",
    "        metric=metric,\n",
    "    )\n",
    "    mean = lambda x: sum(x) / len(x)\n",
    "\n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME, name=args.name,\n",
    "        config=vars(args)\n",
    "    )\n",
    "    for e in range(args.num_epochs):\n",
    "        print(f\"Epoch {e}\")\n",
    "        with_testing = (e == args.num_epochs - 1)\n",
    "        epoch_stats = trainer(num_epochs=1, with_testing=with_testing)\n",
    "        train_loss, train_metric = epoch_stats['train'][0]\n",
    "        val_loss, val_metric = epoch_stats['val'][0]\n",
    "        assert isinstance(train_loss, list), type(train_loss)\n",
    "        wandb.log({\n",
    "            \"train\": {\"loss\": mean(train_loss), \"metric\": mean(train_metric)},\n",
    "            \"val\": {\"loss\": mean(val_loss), \"metric\": mean(val_metric)}\n",
    "        })\n",
    "    \n",
    "    test_loss, test_metric = epoch_stats['test'][0]\n",
    "    wandb.summary['test.loss'] = mean(test_loss)\n",
    "    wandb.summary['test.metric'] = mean(test_metric)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--name\", type=str, required=True)\n",
    "    parser.add_argument(\"--train-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--test-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--lr\", type=float, required=True)\n",
    "    parser.add_argument(\"--num-epochs\", type=int, required=True)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--device\", type=str, default='cpu:0')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    run_pipeline(args)\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148808e-a6de-49d3-8e7d-ef8b6ee27b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m suim_segmentation.run --name=baseline --lr=0.03 --num-epochs=1 --batch-size=32 --device=cpu:0 \\\n",
    "    --train-data=D:\\edu\\course_cvdl\\classes\\c04\\data\\train_val \\\n",
    "    --test-data=D:\\edu\\course_cvdl\\classes\\c04\\data\\TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d404e7f-9bc2-47d9-ba8d-01952c4d9113",
   "metadata": {},
   "source": [
    "## Запуск в DataSphere\n",
    "```\n",
    "%pip install wandb\n",
    "!python3 -m wandb login <your key>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3236b75c-f9a1-4325-b197-dfb396c07078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/edu/course_cvdl/classes/c04')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "from pathlib import Path\n",
    "ROOT_PATH = Path().absolute()\n",
    "assert ROOT_PATH.name == 'c04', ROOT_PATH.name\n",
    "ROOT_PATH"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18b49dcf-1d4a-48be-8bfb-4f7acb14f2f0",
   "metadata": {},
   "source": [
    "#!g2.mig\n",
    "! cd src & python3 -m suim_segmentation.run --name=baseline --lr=0.03 --num-epochs=20 --batch-size=32 --device=cuda:0 \\\n",
    "    --train-data=/home/jupyter/mnt/datasets/SUIM_Dataset/train_val \\\n",
    "    --test-data=/home/jupyter/mnt/datasets/SUIM_Dataset/TEST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f617bff-6cb2-4c4e-8ab1-dc23a8dbcd9a",
   "metadata": {},
   "source": [
    "## 4. Добавим в пайплайн аугментаций `albumentations`\n",
    "https://albumentations.ai/docs/examples/pytorch_semantic_segmentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1fab2-98d1-43f8-8bdd-36ab944d0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "from suim_segmentation.data import SuimDataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "AUG = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomSizedCrop(min_max_height=(150, 250), height=256, width=256, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ],p=1),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n",
    "    ], p=0.8),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "class SuimDatasetWAug(SuimDataset):\n",
    "    def __init__(self, *, transform=None, **kwargs):\n",
    "        assert kwargs.get('masks_as_colors', False) == False, \"Not supported\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        img, mask = super().__getitem__(idx)\n",
    "        if self.transform is not None:\n",
    "            results = self.transform(image=img.permute(1, 2, 0).numpy(), mask=mask.numpy()[0])\n",
    "            img = results['image']\n",
    "            mask = results['mask'][None]\n",
    "        return img, mask\n",
    "\n",
    "ds = SuimDatasetWAug(\n",
    "    root=Path('/home/jupyter/mnt/datasets/SUIM_Dataset/TEST'),\n",
    "    masks_as_color=False, \n",
    "    target_size=(256, 256),\n",
    "    transform=AUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f3bef-d779-4cc0-90f7-4514d3bab872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "to_img = transforms.ToPILImage()\n",
    "x, y = ds[2]\n",
    "plt.imshow(to_img(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf94d4de-a151-4ee1-b0fc-e1338cade752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "%%writefile {str(ROOT_PATH / 'src' / 'suim_segmentation' / 'run.py')}\n",
    "import wandb\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as tdata\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from .data import SuimDataset, EveryNthFilterSampler\n",
    "from .model import SuimModel\n",
    "from .loss import DiceLoss\n",
    "from .metrics import Accuracy\n",
    "from .trainer import Trainer\n",
    "\n",
    "PROJECT_NAME = 'suim_segmentation2023'\n",
    "\n",
    "AUG = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomSizedCrop(min_max_height=(150, 250), height=256, width=256, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ],p=1),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1),\n",
    "    ], p=0.8),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "class SuimDatasetWAug(SuimDataset):\n",
    "    def __init__(self, *, transform=None, **kwargs):\n",
    "        assert kwargs.get('masks_as_colors', False) == False, \"Not supported\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        img, mask = super().__getitem__(idx)\n",
    "        if self.transform is not None:\n",
    "            results = self.transform(image=img.permute(1, 2, 0).numpy(), mask=mask.numpy()[0])\n",
    "            img = results['image']\n",
    "            mask = results['mask'][None]\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "def run_pipeline(args):\n",
    "    device = torch.device(args.device)\n",
    "    model = SuimModel().to(device)\n",
    "    model.encoder.requires_grad_(False)\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    if args.with_augs:\n",
    "        train_val_ds = SuimDatasetWAug(\n",
    "            root=Path(args.train_data), masks_as_color=False, target_size=(256, 256),\n",
    "            transform=AUG\n",
    "        )\n",
    "    else:\n",
    "        train_val_ds = SuimDataset(\n",
    "            root=Path(args.train_data), masks_as_color=False, target_size=(256, 256),\n",
    "        )\n",
    "    test_ds = SuimDataset(\n",
    "        root=Path(args.test_data), masks_as_color=False, target_size=(256, 256)\n",
    "    )\n",
    "    test_iter = tdata.DataLoader(test_ds, batch_size=args.batch_size, shuffle=False)\n",
    "    train_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=False, shuffle=True\n",
    "        ),\n",
    "    )\n",
    "    val_iter = tdata.DataLoader(\n",
    "        train_val_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        sampler=EveryNthFilterSampler(\n",
    "            dataset_size=len(train_val_ds), n=5, pass_every_nth=True, shuffle=False\n",
    "        ),\n",
    "    )\n",
    "    loss = DiceLoss()\n",
    "    metric = Accuracy()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        net=model,\n",
    "        opt=opt,\n",
    "        train_loader=train_iter,\n",
    "        val_loader=val_iter,\n",
    "        test_loader=test_iter,\n",
    "        loss=loss,\n",
    "        metric=metric,\n",
    "    )\n",
    "    mean = lambda x: sum(x) / len(x)\n",
    "\n",
    "    wandb.init(\n",
    "        project=PROJECT_NAME, name=args.name,\n",
    "        config=vars(args)\n",
    "    )\n",
    "    for e in range(args.num_epochs):\n",
    "        print(f\"Epoch {e}\")\n",
    "        with_testing = (e == args.num_epochs - 1)\n",
    "        epoch_stats = trainer(num_epochs=1, with_testing=with_testing)\n",
    "        train_loss, train_metric = epoch_stats['train'][0]\n",
    "        val_loss, val_metric = epoch_stats['val'][0]\n",
    "        assert isinstance(train_loss, list), type(train_loss)\n",
    "        wandb.log({\n",
    "            \"train\": {\"loss\": mean(train_loss), \"metric\": mean(train_metric)},\n",
    "            \"val\": {\"loss\": mean(val_loss), \"metric\": mean(val_metric)}\n",
    "        })\n",
    "\n",
    "    test_loss, test_metric = epoch_stats['test'][0]\n",
    "    wandb.summary['test.loss'] = mean(test_loss)\n",
    "    wandb.summary['test.metric'] = mean(test_metric)\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--name\", type=str, required=True)\n",
    "    parser.add_argument(\"--train-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--test-data\", type=str, required=True)\n",
    "    parser.add_argument(\"--lr\", type=float, required=True)\n",
    "    parser.add_argument(\"--num-epochs\", type=int, required=True)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=16)\n",
    "    parser.add_argument(\"--device\", type=str, default='cpu:0')\n",
    "    parser.add_argument(\"--with-augs\", action='store_true')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    run_pipeline(args)\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83153e-f622-45f8-8116-a67243fb7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "! cd src & python3 -m suim_segmentation.run --name=baseline-with_augs --lr=0.03 --num-epochs=20 --batch-size=32 --device=cuda:0 \\\n",
    "    --train-data=/home/jupyter/mnt/datasets/SUIM_Dataset/train_val \\\n",
    "    --test-data=/home/jupyter/mnt/datasets/SUIM_Dataset/TEST --with-augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70831984-613f-4deb-9884-683c88fd6f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
